---
title: "Kaggle RSNA 2022 1st Place Solution"
emoji: "ğŸ”–"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["kaggle",]
published: false
---

# RSNA 2022 1st Solution 

## ãƒ¢ãƒ‡ãƒ«æ§‹é€ 

- 2ã‚¹ãƒ†ãƒ¼ã‚¸ã®ãƒ¢ãƒ‡ãƒ«
  - ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã€åˆ†é¡å•é¡Œã‚’åˆ¥å€‹ã«è§£ã„ã¦ã„ã‚‹
- Stage1
  - 3D semantic segmentation
- Stage2
  - 2.5D w/ LSTM classification
  - äºŒç¨®é¡ã® classification model ã‚’ä½œæˆã—ãŸ


## 3D semantic segmentation

- 87 ã‚µãƒ³ãƒ—ãƒ«ã® 3D ãƒã‚¹ã‚¯ã§å­¦ç¿’ã—ãŸ
  - å°‘æ•°ã‚µãƒ³ãƒ—ãƒ«ã ã£ãŸãŒååˆ†ã ã£ãŸã®ã“ã¨  
- å…¥åŠ›
  - 128x128x128 ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
- ãƒ¢ãƒ‡ãƒ«
  - EfficientNetV2 + UNet
- å‡ºåŠ›
  - 7ãƒãƒ£ãƒ³ãƒãƒ«ã®å‡ºåŠ›
  - å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ãŒäºˆæ¸¬ã™ã‚‹3Dãƒã‚¹ã‚¯ã¯å¾Œæ®µã®ã‚¿ã‚¹ã‚¯ã§ä½¿ç”¨ã™ã‚‹

## Classification model

- å„è„Šæ¤ï¼ˆvertabraeï¼‰ã®3Dãƒã‚¹ã‚¯ã‚’äºˆæ¸¬ã—ãŸ
  - 1æšã®3Dç”»åƒã‹ã‚‰7ç®‡æ‰€ã®è„Šæ¤ã‚’ã‚¯ãƒ­ãƒƒãƒ—ã™ã‚‹ã“ã¨ãŒã§ãã‚‹
  - crop å†…ã«è¤‡æ•°ã®è„Šæ¤ãŒæ˜ ã‚‹ã“ã¨ã‚‚åˆã£ãŸãŒå¤§ä¸ˆå¤«ã ã£ãŸã¨ã®ã“ã¨
  - 2k ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦7ç®‡æ‰€ã‚’ãã‚Œãã‚Œåˆ‡ã‚Šå‡ºã™ã®ã§ã€åˆè¨ˆ14k ã‚µãƒ³ãƒ—ãƒ«ãŒä½œæˆã•ã‚Œã‚‹
- å…¥åŠ›
  - 128x128x30
  - zè»¸æ–¹å‘ã«15ã‚¹ãƒ©ã‚¤ã‚¹å–ã‚Šå‡ºã—ã¦ã€å„ã‚¹ãƒ©ã‚¤ã‚¹ã«å¯¾ã—ã¦Â±2ã‚¹ãƒ©ã‚¤ã‚¹å‰å¾Œã®ã‚‚ã®ã‚’å–ã‚Šå‡ºã—ã¦å…¥åŠ›æƒ…å ±ã‚’ä½œæˆã™ã‚‹


### type-1 

- 14k 3D å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒã‚ã£ã¦ã€å˜ç´”ã«ã¯ 3D CNN ã‚’ä½¿ç”¨ã™ã‚‹ã®ãŒã‚ˆã•ãã†ã ãŒãã‚Œã¯æœ‰åŠ¹ã§ã¯ãªã‹ã£ãŸã‚ˆã†ã 
  - ãã®ãŸã‚ 3D CNN ã§ã¯ãªã 2.5D CNN ã‚’ä½¿ç”¨ã—ãŸ
  - 2.5D ã¨ã¯å„ã‚¹ãƒ©ã‚¤ã‚¹ã‚’ concat ã—ãŸã‚‚ã®ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã¨ã„ã†æ„å‘³

![](https://storage.googleapis.com/zenn-user-upload/78c41f836e3a-20230903.png)

- å…¥åŠ›
  - 15ã‚¹ãƒ©ã‚¤ã‚¹ã‚’ CNN ã«å…¥åŠ›ã—ã€å„ã‚¹ãƒ©ã‚¤ã‚¹ã«å¯¾å¿œã—ãŸç‰¹å¾´é‡ã‚’æŠ½å‡ºã™ã‚‹

### type-2


![](https://storage.googleapis.com/zenn-user-upload/bcc57e863c55-20230903.png)



# é›‘è¨˜

## ãƒ‡ãƒ¼ã‚¿æ§‹é€ 

- `[train/test]_images/[StudyInstanceUID]/[slice_number].dcm`
  - StudyInstanceUID : å„ patient ã‚¹ã‚­ãƒ£ãƒ³ã«å€‹åˆ¥ã®IDï¼ˆæ‚£è€…IDã«å¯¾å¿œã—ã¦ã„ãªã„ï¼‰
  - æ°—æŒã¡çš„ã«ã¯ `train_images/patient_id/scan_id/slice_number.dcm` ã®ã‚ˆã†ãªã‚‚ã®
- `segmentations` 
  - å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ä¸€éƒ¨ã«ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚Œã¦ã„ã‚‹ pixel ãƒ¬ãƒ™ãƒ«ã® annotation ãƒ‡ãƒ¼ã‚¿
    - 3D Unet ã§è‡ªå‹•ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚Œã¦ã„ã‚‹
  - niftiã€€ãƒ‡ãƒ¼ã‚¿ã§ãƒ•ã‚¡ã‚¤ãƒ«åãŒ StudyInstanceUID ã‚’æŒã£ã¦ã„ã‚‹
  - train ãƒ‡ãƒ¼ã‚¿ã®ä¸­ã§ã€€segmentation æƒ…å ±ã‚’æŒã£ã¦ã„ã‚‹ã‚‚ã®ã¯ä¸€éƒ¨ãªã®ã§ã€é©å®œ DataFrame ã®ãƒãƒ¼ã‚¸ã«æ°—ã‚’ã¤ã‘ã‚‹

## Stage 1 ([notebook](https://www.kaggle.com/code/haqishen/rsna-2022-1st-place-solution-train-stage1))

### ãƒ‡ãƒ¼ã‚¿

- Dataset
  - 128x128x128 ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã©ã®ã‚ˆã†ã«ä½œæˆã—ã¦ã„ã‚‹ã®ã‹ã¯ä»¥ä¸‹ã®é€šã‚Šã€‚
  - ä»Šå›ã¯ `StudyInstanceUID` ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ 128ã€€æšã‚’å–å¾—ã™ã‚‹ã‚«ãƒ©ã‚¯ãƒªã¯ `np.quantile` ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹
  - ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä»¥ä¸‹ã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒ10å€‹ã‚ã£ã¦ãã“ã‹ã‚‰5å€‹å–ã‚ŠãŸã„ã¨ãã¯ã€0, 2, 4, 7, 9 ã¨é–“å¼•ã„ã¦å–ã£ã¦ãã‚‹ã‚ˆã†ã«ã—ã¦ã€5å€‹æœªæº€ã®éš›ã«ã¯é‡è¤‡ã—ã¦å–ã£ã¦ãã‚‹ã‚ˆã†ã«ã—ã¦ã„ã‚‹ã€‚ã“ã†ã™ã‚‹ã“ã¨ã§ï¼ˆãƒ‡ãƒ¼ã‚¿ã®é‡è¤‡ã¯ã‚ã‚Œã©ï¼‰128æ¬¡å…ƒã®æ·±ã•ã‚’ç¢ºå®Ÿã«æ‹…ä¿ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹

```python
>>> np.quantile(list(range(10)), np.linspace(0, 1, 5)).round()
array([0., 2., 4., 7., 9.])
>>> np.quantile(list(range(2)), np.linspace(0, 1, 5)).round()
array([0., 0., 0., 1., 1.])
```

### ãƒ¢ãƒ‡ãƒ«

- segmentation model ã‚’ä½œæˆã™ã‚‹ã¨ãã¯ `timm` ã® `features_only=True` ã‚’ä½¿ç”¨ã™ã‚‹
  - https://huggingface.co/docs/timm/feature_extraction
  - ãƒ¢ãƒ‡ãƒ«ã®ä¸­é–“ç‰¹å¾´é‡ã‚’æœ€å¤§5å€‹ã¾ã§å–å¾—ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€‚Unetã‚’ä½œæˆã™ã‚‹ã¨ãã«é‡å®ã™ã‚‹
  - ä»Šå›ã¯ encoder ã« `resnet18d`ã€ decoder ã« Unet ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹
- æå¤±é–¢æ•°ã¯ binary dice loss ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹
- ã‚¨ãƒãƒƒã‚¯ã‚’å›ã™ã¨ãã« `train_func`ã€`valid_func` ã¨ã„ã†é–¢æ•°ã‚’ä½œæˆã—ã¦ã„ã‚‹
  - ãƒ¢ãƒ‡ãƒ«ã€DataLoader ãªã©ã‚’å¼•æ•°ã«å–ã£ã¦ã„ã‚‹ï¼ˆtrain ã®ã»ã†ã¯ optimzer, scaler ã‚‚å–ã‚‹ï¼‰
- ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã« `torch.optim.lr_scheduler.CosineAnnealingWarmRestarts` ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹


## Stage2 [notebook](https://www.kaggle.com/code/haqishen/rsna-2022-1st-place-solution-train-stage2-type1)

- 3D segmentation model ã‚’ stage-1 ã§ä½œæˆã—ã¦ã„ã‚‹ã®ã§ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å…¨ä½“ã«å¯¾ã—ã¦ã‚‚ãƒã‚¹ã‚¯ã‚’ä½œæˆã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚‹
  - Stageã«åˆ†ã‘ã¦ã„ã‚‹ã®ã¯ã€ãã‚‚ãã‚‚ 3D ãƒã‚¹ã‚¯ãŒå…¨å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ä¸ãˆã‚‰ã‚Œã¦ã„ãªã„ã“ã¨ã«ã‚‚èµ·å› ã™ã‚‹ã¨æ€ã‚ã‚Œã‚‹
  - äºˆæ¸¬ãƒã‚¹ã‚¯ã‚’ä½¿ã£ã¦ã‚¯ãƒ­ãƒƒãƒ—ï¼ˆå¯¾è±¡éƒ¨åˆ†ã ã‘ã‚’æŠ½å‡ºï¼‰ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹


### ãƒ¢ãƒ‡ãƒ«

- LSTM ã¯ `torch.nn.LSTM` ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹

```python
self.lstm = nn.LSTM(hdim, 256, num_layers=2, dropout=drop_rate, bidirectional=True, batch_first=True)
```

- config
    - image_size = 224
    - n_slice_per_c = 15
    - in_chans = 6
- ã¾ãš `encoder` ã«é€šã—ã¦å‡ºåŠ›ã™ã‚‹
- å‡ºåŠ›ã¯ `view` ã‚’ä½¿ã£ã¦ LSTM ã§æ‰±ãˆã‚‹å½¢çŠ¶ã«ã™ã‚‹
  - `view` ã¯ reshape ã¿ãŸã„ãªã‚‚ã‚“
  - è‡ªåˆ†ã ã£ãŸã‚‰ç›´æ¥ encoder ã®å‡ºåŠ›ã‚’ãã†ã„ã†å½¢ã«ã—ã¦ã—ã¾ã£ã¦ã„ã‚‹ã“ã‚ã ãŒã€ãã†ã§ã¯ãªãã¦ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã®å¾Œå‡¦ç†ã¨ã—ã¦å…¥ã‚Œã‚Œã°è‰¯ã„ã®ã ãªã¨å­¦ã‚“ã 

```python
    def forward(self, x):  # (bs, nslice, ch, sz, sz)
        bs = x.shape[0]
        x = x.view(bs * n_slice_per_c, in_chans, image_size, image_size)
        feat = self.encoder(x)
        feat = feat.view(bs, n_slice_per_c, -1)
        feat, _ = self.lstm(feat)
        feat = feat.contiguous().view(bs * n_slice_per_c, -1)
        feat = self.head(feat)
        feat = feat.view(bs, n_slice_per_c).contiguous()

        return feat
```

- ãã®ä»–
  - AdamW, GradScaler 
  - torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs, eta_min=eta_min)
  - train_func ã®å®šç¾©ã¯ä»¥ä¸‹ã®é€šã‚Š

```python
def train_func(model, loader_train, optimizer, scaler=None):
    model.train()
    train_loss = []
    bar = tqdm(loader_train)
    for images, targets in bar:
        optimizer.zero_grad()
        images = images.cuda()
        targets = targets.cuda()
        
        do_mixup = False
        if random.random() < p_mixup:
            do_mixup = True
            images, targets, targets_mix, lam = mixup(images, targets)

        with amp.autocast(): # ã“ã“ã‚‰ã¸ã‚“ã§ GradScaler ã®ä½¿ç”¨
            logits = model(images)
            loss = criterion(logits, targets)
            if do_mixup:
                loss11 = criterion(logits, targets_mix)
                loss = loss * lam  + loss11 * (1 - lam)
        train_loss.append(loss.item()) 
        scaler.scale(loss).backward() # scaler ã§ backward
        scaler.step(optimizer)        # step
        scaler.update()               # update

        bar.set_description(f'smth:{np.mean(train_loss[-30:]):.4f}')

    return np.mean(train_loss)
```

- ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã‚‚å«ã‚ãŸå­¦ç¿’ãƒ«ãƒ¼ãƒ—ã¯ä»¥ä¸‹ã®é€šã‚Š
  - ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼è‡ªä½“ã€å­¦ç¿’ç‡ã‚’èª¿æ•´ã™ã‚‹ã‚‚ã®ãªã®ã§ train_func ã¨ã‹ã«ã¯é–¢ä¿‚ã—ã¦ã“ãªãã¦ã€å„ã‚¨ãƒãƒƒã‚¯ã®é ­ã§ï¼ˆå¾Œã‚ã§ã‚‚ã„ã„ã¨æ€ã†ãŒï¼‰`step` ã‚’å‘¼ã³å‡ºã™ã¨å­¦ç¿’ç‡ãŒè‡ªå‹•ã§èª¿æ•´ã•ã‚Œã‚‹ã‚‚ã®ã¨ãªã‚‹

```python
scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, n_epochs, eta_min=eta_min)

print(len(dataset_train), len(dataset_valid))

for epoch in range(1, n_epochs+1):
    scheduler_cosine.step(epoch-1)

    print(time.ctime(), 'Epoch:', epoch)

    train_loss = train_func(model, loader_train, optimizer, scaler)
    valid_loss = valid_func(model, loader_valid)
    ...
```


# æ„Ÿæƒ³

- ã©ã†ã‚„ã£ã¦ 128æ¬¡å…ƒã®æ·±ã•ã‚’æ‹…ä¿ã—ã¦ã„ã‚‹ã®ã‹ã¨æ€ã£ãŸãŒã€æ¡ˆå¤–é©å½“ã§ã„ã„ã®ã ã¨å®‰å¿ƒã—ãŸ
- `train_func` ã¿ãŸã„ãªã‚‚ã®ã‚’ä½œã£ãŸã»ã†ãŒè¦‹ã‚„ã™ã„ãªã¨æ€ã£ãŸ